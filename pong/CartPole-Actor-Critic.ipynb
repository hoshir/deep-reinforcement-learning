{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "Below, we will learn to implement and train a policy to play atari-pong, using only the pixels as input. We will use convolutional neural nets, multiprocessing, and pytorch to implement and train our policy. Let's get started!\n",
    "\n",
    "(I strongly recommend you to try this notebook on the Udacity workspace first before running it locally on your desktop/laptop, as performance might suffer in different environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import progressbar as pb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from apex import amp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# check which device is being used.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "print(env.action_space.n)\n",
    "print(env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To speed up training, we can simplify the input by cropping the images and use every other pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "while True:\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(np.random.choice(env.env.action_space.n))\n",
    "    if done:\n",
    "        break\n",
    "time.sleep(1)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy\n",
    "\n",
    "## Exercise 1: Implement your policy\n",
    " \n",
    "Here, we define our policy. The input is the stack of two different frames (which captures the movement), and the output is a number $P_{\\rm right}$, the probability of moving left. Note that $P_{\\rm left}= 1-P_{\\rm right}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, num_input=4, num_output=2):\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        num_hidden1 = 300\n",
    "        num_hidden2 = 200\n",
    "\n",
    "        self.fc1 = nn.Linear(num_input, num_hidden1)\n",
    "        self.fc2 = nn.Linear(num_hidden1, num_hidden2)\n",
    "        self.fc3 = nn.Linear(num_hidden2, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, num_input=4, num_output=1):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        num_hidden1 = 300\n",
    "        num_hidden2 = 200\n",
    "\n",
    "        self.fc1 = nn.Linear(num_input, num_hidden1)\n",
    "        self.fc2 = nn.Linear(num_hidden1 + 1, num_hidden2)\n",
    "        self.fc3 = nn.Linear(num_hidden2, num_output)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        xs = F.relu(self.fc1(state))\n",
    "        x = torch.cat((xs, action), dim=1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We are now ready to train our policy!\n",
    "WARNING: make sure to turn on GPU, which also enables multicore processing. It may take up to 45 minutes even with GPU enabled, otherwise it will take much longer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, score: 16.530000\n",
      "Episode: 200, score: 21.900000\n",
      "Episode: 300, score: 15.350000\n",
      "Episode: 400, score: 12.170000\n",
      "Episode: 500, score: 12.440000\n",
      "Episode: 600, score: 32.340000\n",
      "Episode: 700, score: 10.610000\n",
      "Episode: 763, score: 17.290000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-125cba02aa13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/python-rl/lib/python3.8/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/python-rl/lib/python3.8/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%r (%s) invalid\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/python-rl/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array_repr_implementation\u001b[0;34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[1;32m   1445\u001b[0m         \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m         lst = array2string(arr, max_line_width, precision, suppress_small,\n\u001b[0m\u001b[1;32m   1448\u001b[0m                            ', ', prefix, suffix=suffix)\n\u001b[1;32m   1449\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# show zero-length shape unless it is (0,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/python-rl/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_array2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/python-rl/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/python-rl/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, options, separator, prefix)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;31m# find the right formatting function for the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0mformat_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_format_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;31m# skip over \"[\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/python-rl/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_get_format_function\u001b[0;34m(data, **options)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mdtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mdtypeobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mformatdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_formatdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypeobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/python-rl/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_get_formatdict\u001b[0;34m(data, precision, floatmode, suppress, sign, legacy, formatter, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m def _get_formatdict(data, *, precision, floatmode, suppress, sign, legacy,\n\u001b[0m\u001b[1;32m    368\u001b[0m                     formatter, **kwargs):\n\u001b[1;32m    369\u001b[0m     \u001b[0;31m# note: extra arguments in kwargs are ignored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episode = 5000\n",
    "\n",
    "state = env.reset()\n",
    "\n",
    "gamma = .99\n",
    "actor_lr = 1e-4\n",
    "critic_lr = 1e-4\n",
    "\n",
    "actor = Actor().to(device)\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=actor_lr)\n",
    "\n",
    "critic = Critic().to(device)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=critic_lr)\n",
    "\n",
    "# keep track of progress\n",
    "total_rewards = deque(maxlen=100)\n",
    "\n",
    "critic_loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "for i in range(1, episode+1):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    states = []\n",
    "    actions = []\n",
    "    next_actions = []\n",
    "    next_states = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    log_probs = []\n",
    "    done = False\n",
    "    while not done:\n",
    "        state_tensor = torch.tensor(state).float().to(device)\n",
    "\n",
    "        probs_tensor = actor(state_tensor)\n",
    "        m = Categorical(logits=probs_tensor)\n",
    "        action_tensor = m.sample()\n",
    "        action = action_tensor.detach().cpu().numpy()\n",
    "        log_prob = m.log_prob(action_tensor).detach().cpu().item()\n",
    "        \n",
    "        # Step\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        next_states.append(next_state)\n",
    "        dones.append(done)\n",
    "        log_probs.append(log_prob)\n",
    "        \n",
    "        total_rewards.append(total_reward)\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 1\n",
    "        rewards.append(reward)\n",
    "        total_reward += reward\n",
    "\n",
    "#     discounts = gamma ** np.arange(len(rewards))\n",
    "#     rewards = np.asarray(rewards) * discounts\n",
    "#     rewards_future = rewards[::-1].cumsum(axis=0)[::-1]\n",
    "    rewards_future = np.array(rewards)\n",
    "\n",
    "\n",
    "#     print(rewards_future)\n",
    "#     break\n",
    "    actions = np.array(actions)\n",
    "\n",
    "    states_tensor = torch.tensor(states).float().to(device)\n",
    "    actions_tensor = torch.tensor(actions).float().to(device).unsqueeze(1)\n",
    "    next_states_tensor = torch.tensor(next_states).float().to(device)\n",
    "    rewards_tensor = torch.tensor(rewards_future.tolist()).float().to(device).unsqueeze(1)\n",
    "    dones_tensor = torch.tensor(dones).float().to(device).unsqueeze(1)\n",
    "\n",
    "    # Critic target\n",
    "    probs_tensor = actor(next_states_tensor)\n",
    "    m = Categorical(logits=probs_tensor)\n",
    "    next_actions_tensor = m.sample().unsqueeze(1)\n",
    "        \n",
    "    vs_next = critic(next_states_tensor, next_actions_tensor)\n",
    "    vs_target = rewards_tensor + gamma * vs_next * (1 - dones_tensor)\n",
    "\n",
    "    # Critic expected\n",
    "    vs = critic(states_tensor, actions_tensor)\n",
    "\n",
    "    critic_loss = critic_loss_fn(vs, vs_target)\n",
    "    critic_optimizer.zero_grad()\n",
    "    critic_loss.backward()\n",
    "    critic_optimizer.step()\n",
    "\n",
    "    states_tensor = torch.tensor(states).float().to(device)\n",
    "    next_states_tensor = torch.tensor(next_states).float().to(device)\n",
    "    rewards_tensor = torch.tensor(rewards_future.tolist()).float().to(device).unsqueeze(1)\n",
    "    dones_tensor = torch.tensor(dones).float().to(device).unsqueeze(1)\n",
    "    log_probs_tensor = torch.tensor(log_probs).float().to(device).unsqueeze(1)\n",
    "    \n",
    "    # A(a, s)\n",
    "    probs_tensor = actor(next_states_tensor)\n",
    "    m = Categorical(logits=probs_tensor)\n",
    "    next_actions_tensor = m.sample().unsqueeze(1)\n",
    "#     advantage = rewards_tensor + gamma * critic(next_states_tensor, next_actions_tensor) * (1 - dones_tensor) - critic(states_tensor, actions_tensor)\n",
    "\n",
    "#     actor_loss = (-log_probs_tensor * advantage)\n",
    "    actor_loss = -log_probs_tensor * critic(states_tensor, actions_tensor)\n",
    "    actor_loss = actor_loss.sum()\n",
    "#     print(actor_loss)\n",
    "\n",
    "    actor_optimizer.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    actor_optimizer.step()\n",
    "\n",
    "\n",
    "    # display some progress every 20 iterations\n",
    "    print(\"\\rEpisode: {0:d}, score: {1:f}\".format(i, np.mean(total_rewards)), end=\"\")\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\rEpisode: {0:d}, score: {1:f}\".format(i, np.mean(total_rewards)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state = env.reset()\n",
    "while True:\n",
    "    env.render()\n",
    "    with torch.no_grad():\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float).to(device)\n",
    "\n",
    "        # Decide action\n",
    "        probs_tensor = actor(state_tensor)\n",
    "        m = Categorical(logits=probs_tensor)\n",
    "        action_tensor = m.sample()\n",
    "        action = action_tensor.detach().cpu().numpy()\n",
    "\n",
    "        # Step\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "time.sleep(1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([0], maxlen=3)\n",
      "deque([0, 1], maxlen=3)\n",
      "deque([0, 1, 2], maxlen=3)\n",
      "deque([1, 2, 3], maxlen=3)\n",
      "deque([2, 3, 4], maxlen=3)\n"
     ]
    }
   ],
   "source": [
    "a = deque(maxlen=3)\n",
    "for i in range(5):\n",
    "    a.append(i)\n",
    "    print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
